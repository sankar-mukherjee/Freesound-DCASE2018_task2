{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://github.com/aqibsaeed/Urban-Sound-Classification/blob/master/Urban%20Sound%20Classification%20using%20RNN.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "train_path = '../input/audio_train/'\n",
    "test_path = '../input/audio_test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "      <th>manually_verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00044347.wav</td>\n",
       "      <td>Hi-hat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001ca53d.wav</td>\n",
       "      <td>Saxophone</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002d256b.wav</td>\n",
       "      <td>Trumpet</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0033e230.wav</td>\n",
       "      <td>Glockenspiel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00353774.wav</td>\n",
       "      <td>Cello</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname         label  manually_verified\n",
       "0  00044347.wav        Hi-hat                  0\n",
       "1  001ca53d.wav     Saxophone                  1\n",
       "2  002d256b.wav       Trumpet                  0\n",
       "3  0033e230.wav  Glockenspiel                  1\n",
       "4  00353774.wav         Cello                  1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label\n",
    "train_label = pd.read_csv(\"../input/train.csv\")\n",
    "test_label = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "\n",
    "\n",
    "train_label.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = train_label['fname'].get_values()\n",
    "files_labels = train_label['label'].get_values()\n",
    "\n",
    "bands = 20\n",
    "frames = 41\n",
    "window_size = 512 * (frames - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0,
     7
    ]
   },
   "outputs": [],
   "source": [
    "def windows(data, window_size):\n",
    "    start = 0\n",
    "    while start < len(data):\n",
    "        yield start, start + window_size\n",
    "        start += (window_size / 2)\n",
    "\n",
    "        \n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     5
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 "
     ]
    }
   ],
   "source": [
    "\n",
    "mfccs = []\n",
    "labels = []\n",
    "\n",
    "#for fn in range(0,len(files)):\n",
    "for fn in range(0,100):\n",
    "    print(str(fn), end=' ')\n",
    "    sound_clip,s = librosa.load(train_path+files[fn])\n",
    "    for (start,end) in windows(sound_clip,window_size):\n",
    "        start = int(start)\n",
    "        end = int(end)\n",
    "        if(len(sound_clip[start:end]) == window_size):\n",
    "            signal = sound_clip[start:end]\n",
    "            mfcc = librosa.feature.mfcc(y=signal, sr=s, n_mfcc = bands).T.flatten()[:, np.newaxis].T\n",
    "            mfccs.append(mfcc)\n",
    "            labels.append(files_labels[fn]) \n",
    "            \n",
    "features = np.asarray(mfccs).reshape(len(mfccs),frames,bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_features = np.array(features)\n",
    "tr_labels = np.array(labels)\n",
    "\n",
    "LABELS = np.unique(tr_labels)\n",
    "label_idx = {label: i for i, label in enumerate(LABELS)}\n",
    "vfunc = np.vectorize(lambda x: label_idx[x])\n",
    "tr_labels=vfunc(tr_labels)\n",
    "\n",
    "tr_labels = one_hot_encode(tr_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     5
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 "
     ]
    }
   ],
   "source": [
    "files = test_label['fname'].get_values()\n",
    "\n",
    "mfccs = []\n",
    "\n",
    "#for fn in range(0,len(files)):\n",
    "for fn in range(0,10):\n",
    "    print(str(fn), end=' ')\n",
    "    sound_clip,s = librosa.load(test_path+files[fn])\n",
    "    for (start,end) in windows(sound_clip,window_size):\n",
    "        start = int(start)\n",
    "        end = int(end)\n",
    "        if(len(sound_clip[start:end]) == window_size):\n",
    "            signal = sound_clip[start:end]\n",
    "            mfcc = librosa.feature.mfcc(y=signal, sr=s, n_mfcc = bands).T.flatten()[:, np.newaxis].T\n",
    "            mfccs.append(mfcc)\n",
    "            \n",
    "features = np.asarray(mfccs).reshape(len(mfccs),frames,bands)\n",
    "\n",
    "ts_features = np.array(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "learning_rate = 0.01\n",
    "training_iters = 1000\n",
    "batch_size = 50\n",
    "display_step = 200\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 20 \n",
    "n_steps = 41\n",
    "n_hidden = 300\n",
    "n_classes = np.unique(labels).shape[0]\n",
    "\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "weight = tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def RNN(x, weight, bias):\n",
    "    #cell = rnn_cell.LSTMCell(n_hidden,state_is_tuple = True)\n",
    "    #cell = rnn_cell.MultiRNNCell([cell] * 2)\n",
    "    \n",
    "    # create 2 LSTMCells\n",
    "    rnn_layers = [tf.nn.rnn_cell.LSTMCell(size) for size in [n_hidden, n_hidden]]\n",
    "    # create a RNN cell composed sequentially of a number of RNNCells\n",
    "    multi_rnn_cell = tf.nn.rnn_cell.MultiRNNCell(rnn_layers)\n",
    "    \n",
    "    output, state = tf.nn.dynamic_rnn(cell=multi_rnn_cell, inputs=x, dtype = tf.float32)\n",
    "    output = tf.transpose(output, [1, 0, 2])\n",
    "    last = tf.gather(output, int(output.get_shape()[0]) - 1)\n",
    "    return tf.nn.softmax(tf.matmul(last, weight) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EspVicon\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "prediction = RNN(x, weight, bias)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_f = -tf.reduce_sum(y * tf.log(prediction))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss_f)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "#to create the graph summary\n",
    "writer = tf.summary.FileWriter('logdir', session.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    \n",
    "    for itr in range(2):    \n",
    "        offset = (itr * batch_size) % (tr_labels.shape[0] - batch_size)\n",
    "        batch_x = tr_features[offset:(offset + batch_size), :, :]\n",
    "        batch_y = tr_labels[offset:(offset + batch_size), :]\n",
    "        _, c = session.run([optimizer, loss_f],feed_dict={x: batch_x, y : batch_y})\n",
    "            \n",
    "       \n",
    "    #print('Test accuracy: ',round(session.run(accuracy, feed_dict={x: ts_features, y: ts_labels}) , 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
